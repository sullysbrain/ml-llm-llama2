## Building AI LLM App with LangChain, Streamlit, and Llama 2

I built out a web deployed LLM built with the help of LangChain and 'deployed' locally as a locally hosted server using StreamLit. The model itself currently uses the OpenAI API but my intent is to shift over to Meta's and Microsoft's Llama 2.0.

As mentioned above, the web interface uses StreamLit. Next phase will roll out using AWS.

Also interested in adding use of SageMaker and DataIku as part of the pipeline if appropriate.
